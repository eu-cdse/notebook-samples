{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c937629a-b80d-4e4e-885d-44175ca5ef6b",
   "metadata": {},
   "source": [
    "# Terra em Foco Conference: Introduction to Sentinel Hub APIs in CDSE: Part One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23794fe-73b4-43cb-a243-85ecea6560e2",
   "metadata": {},
   "source": [
    "*This notebook was written for a two hour training session at the Terra em Foco, the Portuguese Earth Observation National Conference held in Braga, Portugal 12-13th September 2024.*\n",
    "\n",
    "The Copernicus Data Space Ecosystem offers immediate access to large amounts of open and free Earth observation data from the Copernicus Sentinel satellites, including both new and historical Sentinel images, as well as Copernicus Contributing Missions. As the effects of climate change intensifies, the use of earth observation data will become ever more important to monitor wildfires in the southern Europe including Portugal. These two notebooks will show how you can utilise Copernicus data to do just this.\n",
    "\n",
    "The Copernicus Data Space Ecosystem supports users in accessing, viewing, using, downloading, and analyzing data. The Copernicus Data Space Ecosystem is set up to further improve access and exploitation of the EU’s Copernicus satellites data. The service aims to support users in building various applications needed to provide accurate, timely and objective information which are crucial to create a more sustainable future.\n",
    "\n",
    "The Copernicus Data Space Ecosystem offers multiple Application Programming Interfaces (APIs) ranging from catalogue, product download, visualization over processing web services such as STAC, openEO and Sentinel Hub APIs. This Jupyter notebook focuses on the Sentinel Hub APIs The Sentinel Hub API is a RESTful API interface that provides access to various satellite imagery archives. It allows you to access raw satellite data, rendered images, statistical analysis, and other features.\n",
    "\n",
    "\n",
    "This notebook contains three examples:\n",
    "\n",
    "1. Forest fire detection across south west Portugal utilising Sentinel-3 SLSTR\n",
    "2. Visualisation of the forest fire during the event using Sentinel-2\n",
    "3. Detection and mapping of the burned area post event\n",
    "\n",
    "**Note:** You do not need any prior experience of Sentinel Hub APIs to be able to follow the functions in this notebook. However, it is advised that you should have some basic knowledge of python and its data science libraries.\n",
    "\n",
    "Firstly, before getting started we should import some libraries. In addition, to common data science libraries we will be utilising the [Sentinel Hub Python package](https://sentinelhub-py.readthedocs.io/en/latest/index.html). This comes preinstalled in the Copernicus Data Space Ecosystem Jupyter Lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef2c05-e174-461b-9d0d-6f937799d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import warnings\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "# Plotting\n",
    "import geopandas as gpd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sentinel Hub services\n",
    "from sentinelhub import (\n",
    "    CRS,\n",
    "    DataCollection,\n",
    "    Geometry,\n",
    "    MimeType,\n",
    "    SentinelHubRequest,\n",
    "    SHConfig,\n",
    ")\n",
    "from shapely.geometry import shape\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485eb57-85e4-442f-be96-cbd213750340",
   "metadata": {},
   "source": [
    "In the following cell, we have defined a python function to help us process and visualise the data later on in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c5099-f7d8-43ca-9e50-a52b39b19909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(\n",
    "    image: np.ndarray,\n",
    "    factor: float = 1.0,\n",
    "    clip_range: Optional[Tuple[float, float]] = None,\n",
    "    **kwargs: Any\n",
    ") -> None:\n",
    "    \"\"\"Utility function for plotting RGB images.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "    if clip_range is not None:\n",
    "        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n",
    "    else:\n",
    "        ax.imshow(image * factor, **kwargs)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377a2f5-d38d-4070-b985-d32608c26336",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Authentication\n",
    "\n",
    "You can obtain the credentials for the Sentinel Hub services (`client_id` & `client_secret`) in your [Dashboard](https://shapps.dataspace.copernicus.eu/dashboard/#/). In the user settings, you can create a new OAuth client to generate these credentials. You can find more detailed instructions on the corresponding [documentation page](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Overview/Authentication.html).\n",
    "\n",
    "Now that you have your `client_id` & `client_secret`, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions for configuring your Sentinel Hub Python package can be found [here](https://sentinelhub-py.readthedocs.io/en/latest/configure.html). Using these instructions, you can create a profile specifically tailored to use the package to access the Copernicus Data Space Ecosystem data collections. This is useful because changes to the Config class in your notebook are usually only temporary. If you save the configuration in your profile, you do not have to generate new credentials or overwrite/change the default profile every time you start or write a new Jupyter notebook.\n",
    "\n",
    "If you are using the Sentinel Hub Python package for the Copernicus Data Space Ecosystem for the first time, you should create a profile specifically for the Copernicus Data Space Ecosystem. You can do this in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88cef5a-2fa1-49f7-9b0d-7caecd9b98b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only run this cell if you have not created a configuration.\n",
    "\n",
    "# config = SHConfig()\n",
    "# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n",
    "# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\n",
    "# config.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "# config.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n",
    "# config.save(\"cdse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b4d52-8c4c-435e-a51d-92ecca1b376e",
   "metadata": {},
   "source": [
    "However, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing `<profile_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d5ffb-c793-4e2e-b171-02dffed2b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SHConfig(\"cdse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0936b-3549-4bfd-a74f-241a71bcc114",
   "metadata": {},
   "source": [
    "## 1: Forest fire detection across south west Portugal utilising Sentinel-3 SLSTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf79b4-dc0c-4698-a880-8d08c340f905",
   "metadata": {},
   "source": [
    "In this first example, we will make a processing API request to visualise hotspots using Sentinel-3 SLSTR. \n",
    "\n",
    "Firstly, some information about the AOI and the case study that we will be using for this training. The AOI is located in south west Portugal and was the site of a wildfire in August 2023. Located near the town of Odemira, over 7000 hectares was burnt resulting in the evacuation of 1400 people as over 1000 firefighters were drafted in to fight and control the spread of the fire. [1](https://www.theguardian.com/world/2023/aug/08/firefighters-tackling-blaze-raging-in-southern-portugal-fire) [2](https://www.reuters.com/world/europe/more-than-1000-evacuated-portugal-wildfire-spreads-2023-08-08/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eeb579-0d77-480f-a1e7-d4ddb05a735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = \"\"\"{\n",
    "  \"type\": \"Polygon\",\n",
    "  \"coordinates\": [\n",
    "    [\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.274053\n",
    "      ],\n",
    "      [\n",
    "        -8.178291,\n",
    "        37.274053\n",
    "      ],\n",
    "      [\n",
    "        -8.178291,\n",
    "        37.810869\n",
    "      ],\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.810869\n",
    "      ],\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.274053\n",
    "      ]\n",
    "    ]\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "aoi = gpd.read_file(area_of_interest)\n",
    "aoi[\"geometry\"] = aoi\n",
    "aoi[\"area\"] = aoi.area\n",
    "aoi.explore(\"area\", color=\"Green\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def4c69-4664-47e4-968e-4dd7d3f38cef",
   "metadata": {},
   "source": [
    "If you wish to make your own area of interest you can use the [Request Builder](https://shapps.dataspace.copernicus.eu/requests-builder/) application and draw and AOI using the interface before exporting it into your directory. You can then copy and paste the `geojson` contents into the `area_of_interest` variable in the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf8d18-5afc-4854-93e6-a6ee8d8ffd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_geometry = Geometry(aoi.to_crs(32630).geometry.values[0], crs=CRS.UTM_30N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9d9ed-2721-4732-bdb7-fbfe70ae7d4c",
   "metadata": {},
   "source": [
    "### Processing API\n",
    "\n",
    "The [Processing API](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Process.html) (or shortly \"Process API\") is the most commonly used API in Sentinel Hub as it provides images based on satellite data. Users can request raw satellite data, simple band combinations such as false colour composites, calculations of simple remote sensing indices like NDVI, or more advanced processing such as calculation of Leaf area index (LAI).\n",
    "\n",
    "Even though satellite imagery data are often distributed in \"tiles\", we do not want users to be limited to these. Tiles are an artificially introduced entity to make data distribution easier to handle. However, users should not have to care about whether their AOI is on one tile or another, or perhaps on the border of two tiles. This is why Sentinel Hub API hides this complexity and simply makes the data available over chosen area of interest and temporal period of interest. Tiles are therefore automatically stitched together based on defined parameters (AOI, time period, cloud coverage, priority, etc., depending on the data type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe441139-5901-4872-9adf-b7c4a2916bcd",
   "metadata": {},
   "source": [
    "### Write an Evalscript\n",
    "\n",
    "An [evalscript](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Evalscript.html) (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\n",
    "\n",
    "In the following Evalscript we will perform all the processing steps that we performed in the \"traditional\" approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b8c6c-ef81-4896-b7d2-636581a634ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_fire_detection = \"\"\"\n",
    "// high accuracy Detect active fire points \n",
    "//Sentinel-3 SLSTR\n",
    "//by Tiznger startup co\n",
    "//www.tiznegar.com\n",
    "\n",
    "var SAHM= ((S6 - S5) / (S6 + S5));\n",
    "\n",
    "if(SAHM>.05 && S1<.23){\n",
    "  return[5*S3, 1*S2, 1*S1]\n",
    "}\n",
    "\n",
    "else {\n",
    " return [S6,S3,S2]\n",
    "}\n",
    "\n",
    "//Red color indicates active fire areas and points\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d10ee3b-ff1a-420a-8638-f986d970a9df",
   "metadata": {},
   "source": [
    "### Build the request\n",
    "\n",
    "We build the request according to the [API Reference](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/ApiReference.html), using the `SentinelHubRequest` class. Each Process API request also needs an [evalscript](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Evalscript.html). An evalscript (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any [process](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Process.html), [batch processing](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Batch.html) or [OGC request](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/OGC.html).\n",
    "\n",
    "The information that we specify in the `SentinelHubRequest` object is:\n",
    "- an evalscript,\n",
    "- a list of input data collections with time interval,\n",
    "- a format of the response,\n",
    "- a bounding box and its size (size or resolution).\n",
    "- `mosaickingOrder` (optional): in this example we have used `leastRecent` which will return pixels from the least recent acquisition in the specified time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e82f02-5754-46b3-8c4e-e4e6548748a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_true_color = SentinelHubRequest(\n",
    "    evalscript=evalscript_fire_detection,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL3_SLSTR.define_from(\n",
    "                name=\"s3\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
    "            ),\n",
    "            time_interval=(\"2023-08-06\", \"2023-08-06\"),\n",
    "            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastRecent\"}},\n",
    "        )\n",
    "    ],\n",
    "    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "    geometry=full_geometry,\n",
    "    size=[1000, 920],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574920cd-42a8-4ecc-a3ce-880bb4061b74",
   "metadata": {},
   "source": [
    "The method `get_data()` will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dff8dd-4e9e-4f9b-a821-550358b2b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_color_imgs = request_true_color.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce09318-c3b6-4b62-9c17-6c8d00d5f0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n",
    ")\n",
    "print(\n",
    "    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56d96f-119d-4c51-b97c-049abd1aa0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = true_color_imgs[0]\n",
    "print(f\"Image type: {image.dtype}\")\n",
    "\n",
    "# plot function\n",
    "plot_image(image, factor=1.5 / 255, clip_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7f14a-ec38-4258-a8cd-0d2ee46b9ad2",
   "metadata": {},
   "source": [
    "## 2: Visualising forest fires using Sentinel-2 imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c72be-0a1e-4ee4-ad07-ffd0140ad137",
   "metadata": {},
   "source": [
    "In this second example, we will visualise the wildfire we detected using Sentinel-2 imagery.\n",
    "\n",
    "### Write an Evalscript\n",
    "\n",
    "An [evalscript](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Evalscript.html) (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\n",
    "\n",
    "In the following Evalscript we will visualise the forest fire using the SWIR bands that Sentinel-2 offers. It's important to note this is just a visualisation to illustrate the forest fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db87cb-822b-4809-8e16-69936a160b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_wildfire_visualisation = \"\"\"\n",
    "// VERSION=3\n",
    "// QuickFire V1.0.0 by Pierre Markuse (https://twitter.com/Pierre_Markuse)\n",
    "// Adjusted for use in the Copernicus Browser (https://dataspace.copernicus.eu/browser/)\n",
    "// CC BY 4.0 International (https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "// Copernicus Browser does not have the band CLP, this was replaced with the isCloud() function\n",
    "// but do try to turn off cloudAvoidance if results aren't as expected.\n",
    "\n",
    "function setup() {\n",
    "    return {\n",
    "        input: [\"B02\", \"B03\", \"B04\", \"B08\", \"B8A\", \"B11\", \"B12\", \"dataMask\"],\n",
    "        output: { bands: 4 }\n",
    "    };\n",
    "}\n",
    "\n",
    "function isCloud(samples) {\n",
    "    const NGDR = index(samples.B03, samples.B04);\n",
    "    const bRatio = (samples.B03 - 0.175) / (0.39 - 0.175);\n",
    "    return bRatio > 1 || (bRatio > 0 && NGDR > 0);\n",
    "}\n",
    "\n",
    "function stretch(val, min, max) { return (val - min) / (max - min); }\n",
    "\n",
    "function satEnh(arr, s) {\n",
    "    var avg = arr.reduce((a, b) => a + b, 0) / arr.length;\n",
    "    return arr.map(a => avg * (1 - s) + a * s);\n",
    "}\n",
    "\n",
    "function layerBlend(lay1, lay2, lay3, op1, op2, op3) {\n",
    "    return lay1.map(function (num, index) {\n",
    "        return (num / 100 * op1 + (lay2[index] / 100 * op2) + (lay3[index] / 100 * op3));\n",
    "    });\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "    const hsThreshold = [2.0, 1.5, 1.25, 1.0];\n",
    "    const hotspot = 1;\n",
    "    const style = 1;\n",
    "    const hsSensitivity = 1.0;\n",
    "    const boost = 1.2;\n",
    "\n",
    "    const cloudAvoidance = 1;\n",
    "    const avoidanceHelper = 0.8;\n",
    "\n",
    "    const offset = -0.007;\n",
    "    const saturation = 1.10;\n",
    "    const brightness = 1.40;\n",
    "    const sMin = 0.15;\n",
    "    const sMax = 0.99;\n",
    "\n",
    "    const showBurnscars = 0;\n",
    "    const burnscarThreshold = -0.25;\n",
    "    const burnscarStrength = 0.3;\n",
    "\n",
    "    const NDWI = (sample.B03 - sample.B08) / (sample.B03 + sample.B08);\n",
    "    const NDVI = (sample.B08 - sample.B04) / (sample.B08 + sample.B04);\n",
    "    const waterHighlight = 0;\n",
    "    const waterBoost = 2.0;\n",
    "    const NDVI_threshold = 0.05;\n",
    "    const NDWI_threshold = 0.0;\n",
    "    const waterHelper = 0.1;\n",
    "\n",
    "    const Black = [0, 0, 0];\n",
    "    const NBRindex = (sample.B08 - sample.B12) / (sample.B08 + sample.B12);\n",
    "    const naturalColorsCC = [Math.sqrt(brightness * sample.B04 + offset), Math.sqrt(brightness * sample.B03 + offset), Math.sqrt(brightness * sample.B02 + offset)];\n",
    "    const naturalColors = [(2.5 * brightness * sample.B04 + offset), (2.5 * brightness * sample.B03 + offset), (2.5 * brightness * sample.B02 + offset)];\n",
    "    const URBAN = [Math.sqrt(brightness * sample.B12 * 1.2 + offset), Math.sqrt(brightness * sample.B11 * 1.4 + offset), Math.sqrt(brightness * sample.B04 + offset)];\n",
    "    const SWIR = [Math.sqrt(brightness * sample.B12 + offset), Math.sqrt(brightness * sample.B8A + offset), Math.sqrt(brightness * sample.B04 + offset)];\n",
    "    const NIRblue = colorBlend(sample.B08, [0, 0.25, 1], [[0 / 255, 0 / 255, 0 / 255], [0 / 255, 100 / 255, 175 / 255], [150 / 255, 230 / 255, 255 / 255]]);\n",
    "    const classicFalse = [sample.B08 * brightness, sample.B04 * brightness, sample.B03 * brightness];\n",
    "    const NIR = [sample.B08 * brightness, sample.B08 * brightness, sample.B08 * brightness];\n",
    "    const atmoPen = [sample.B12 * brightness, sample.B11 * brightness, sample.B08 * brightness];\n",
    "    var enhNaturalColors = [0, 0, 0];\n",
    "    for (let i = 0; i < 3; i += 1) { enhNaturalColors[i] = (brightness * ((naturalColors[i] + naturalColorsCC[i]) / 2) + (URBAN[i] / 10)); }\n",
    "\n",
    "    const manualCorrection = [0.04, 0.00, -0.05];\n",
    "\n",
    "    var Viz = layerBlend(URBAN, SWIR, naturalColorsCC, 10, 10, 90); // Choose visualization(s) and opacity here\n",
    "\n",
    "    if (waterHighlight) {\n",
    "        if ((NDVI < NDVI_threshold) && (NDWI > NDWI_threshold) && (sample.B04 < waterHelper)) {\n",
    "            Viz[1] = Viz[1] * 1.2 * waterBoost + 0.1;\n",
    "            Viz[2] = Viz[2] * 1.5 * waterBoost + 0.2;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Viz = satEnh(Viz, saturation);\n",
    "    for (let i = 0; i < 3; i += 1) {\n",
    "        Viz[i] = stretch(Viz[i], sMin, sMax);\n",
    "        Viz[i] += manualCorrection[i];\n",
    "    }\n",
    "\n",
    "    if (hotspot) {\n",
    "        if ((!cloudAvoidance) || (!isCloud(sample) && (sample.B02 < avoidanceHelper))) {\n",
    "            switch (style) {\n",
    "                case 1:\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[0] / hsSensitivity)) return [((boost * 0.50 * sample.B12) + Viz[0]), ((boost * 0.50 * sample.B11) + Viz[1]), Viz[2], sample.dataMask];\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[1] / hsSensitivity)) return [((boost * 0.50 * sample.B12) + Viz[0]), ((boost * 0.20 * sample.B11) + Viz[1]), Viz[2], sample.dataMask];\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[2] / hsSensitivity)) return [((boost * 0.50 * sample.B12) + Viz[0]), ((boost * 0.10 * sample.B11) + Viz[1]), Viz[2], sample.dataMask];\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[3] / hsSensitivity)) return [((boost * 0.50 * sample.B12) + Viz[0]), ((boost * 0.00 * sample.B11) + Viz[1]), Viz[2], sample.dataMask];\n",
    "                    break;\n",
    "                case 2:\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[3] / hsSensitivity)) return [1, 0, 0, sample.dataMask];\n",
    "                    break;\n",
    "                case 3:\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[3] / hsSensitivity)) return [1, 1, 0, sample.dataMask];\n",
    "                    break;\n",
    "                case 4:\n",
    "                    if ((sample.B12 + sample.B11) > (hsThreshold[3] / hsSensitivity)) return [Viz[0] + 0.2, Viz[1] - 0.2, Viz[2] - 0.2, sample.dataMask];\n",
    "                    break;\n",
    "                default:\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (showBurnscars) {\n",
    "        if (NBRindex < burnscarThreshold) {\n",
    "            Viz[0] = Viz[0] + burnscarStrength;\n",
    "            Viz[1] = Viz[1] + burnscarStrength;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return [Viz[0], Viz[1], Viz[2], sample.dataMask];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384b7b4-ce0c-4910-bcda-d5c53ba4bab7",
   "metadata": {},
   "source": [
    "### Build the request\n",
    "\n",
    "We build the request according to the [API Reference](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/ApiReference.html), using the `SentinelHubRequest` class. Each Process API request also needs an [evalscript](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Evalscript.html). An evalscript (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any [process](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Process.html), [batch processing](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Batch.html) or [OGC request](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/OGC.html).\n",
    "\n",
    "The information that we specify in the `SentinelHubRequest` object is:\n",
    "- an evalscript,\n",
    "- a list of input data collections with time interval,\n",
    "- a format of the response,\n",
    "- a bounding box and its size (size or resolution).\n",
    "- `mosaickingOrder` (optional): in this example we have used `leastRecent` which will return pixels from the least recent acquisition in the specified time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8f5f3-0193-49e5-be84-97a4dc7b68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_wildfire_visualisation = SentinelHubRequest(\n",
    "    evalscript=evalscript_wildfire_visualisation,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n",
    "                name=\"s2\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
    "            ),\n",
    "            time_interval=(\"2023-08-07\", \"2023-08-07\"),\n",
    "            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastRecent\"}},\n",
    "        )\n",
    "    ],\n",
    "    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "    geometry=full_geometry,\n",
    "    size=[1000, 920],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1959b5-d314-40b1-9162-d2dfc970a122",
   "metadata": {},
   "source": [
    "The method `get_data()` will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2dec4-9ce7-4c1a-952e-62eab6900f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = request_wildfire_visualisation.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3199b4e-f7fa-43c0-827e-23f5d4f94615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Returned data is of type = {type(imgs)} and length {len(imgs)}.\")\n",
    "print(\n",
    "    f\"Single element in the list is of type {type(imgs[-1])} and has shape {imgs[-1].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df292cbf-82c0-443e-97b1-f44e18f42660",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imgs[0]\n",
    "print(f\"Image type: {image.dtype}\")\n",
    "\n",
    "# plot function\n",
    "plot_image(image, factor=1 / 255, clip_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265dc76-8478-4098-a786-e89087aa95f0",
   "metadata": {},
   "source": [
    "## 3: Mapping and measuring the area of burn scars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c7787-8b67-4d88-b3c3-80e055cabab7",
   "metadata": {},
   "source": [
    "Now we will focus on the post event, using the normalised burn ratio we can visualise the extent of the burn scar very easily. Let's create a more focussed area of interest to map out the burn scar area post event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c14388-a81c-440f-a0fa-ab04376d12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = \"\"\"{\n",
    "  \"type\": \"Polygon\",\n",
    "  \"coordinates\": [\n",
    "    [\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.362517\n",
    "      ],\n",
    "      [\n",
    "        -8.516631,\n",
    "        37.362517\n",
    "      ],\n",
    "      [\n",
    "        -8.516631,\n",
    "        37.628372\n",
    "      ],\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.628372\n",
    "      ],\n",
    "      [\n",
    "        -8.920627,\n",
    "        37.362517\n",
    "      ]\n",
    "    ]\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "aoi = gpd.read_file(area_of_interest)\n",
    "aoi_simplified = aoi.geometry.simplify(0.001)\n",
    "aoi[\"geometry\"] = aoi_simplified\n",
    "aoi[\"area\"] = aoi.area\n",
    "aoi.explore(\"area\", color=\"Green\", legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d5183-15f3-4b7b-b725-a5ff5545f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_geometry = Geometry(aoi.to_crs(32630).geometry.values[0], crs=CRS.UTM_30N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c456ac3-5f13-494e-ac8e-0ac72271b3d2",
   "metadata": {},
   "source": [
    "### Write an Evalscript & Build the Request\n",
    "This time we have combined the evalscript and the API request into a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9524bd-8c05-44a4-ada9-d1f0df46c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_burn_scar_map = \"\"\"\n",
    "//VERSION=3\n",
    "// Burneed area detection\n",
    "// Author: Monja B. Šebela\n",
    "\n",
    "function setup() {\n",
    "    return {\n",
    "        input: [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\", \"dataMask\"],\n",
    "        output: { bands: 4 }\n",
    "      };\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "\tvar NDWI=index(samples.B03, samples.B08); \n",
    "\tvar NDVI=index(samples.B08, samples.B04);\n",
    "\tvar INDEX= ((samples.B11 - samples.B12) / (samples.B11 + samples.B12))+(samples.B08);\n",
    "\n",
    "  \tif((INDEX>0.2)||(samples.B02>0.1)||(samples.B11<0.1)||(NDVI>0.3)||(NDWI > 0.1)){\n",
    "  \t\treturn[2.5*samples.B04, 2.5*samples.B03, 2.5*samples.B02, samples.dataMask]\n",
    "\t}\n",
    "\telse {\n",
    " \treturn [1, 0, 0, samples.dataMask]\n",
    "\t}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "request_burn_scar_map = SentinelHubRequest(\n",
    "    evalscript=evalscript_burn_scar_map,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n",
    "                name=\"s2\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
    "            ),\n",
    "            time_interval=(\"2023-08-10\", \"2023-08-15\"),\n",
    "            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastRecent\"}},\n",
    "        )\n",
    "    ],\n",
    "    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "    geometry=full_geometry,\n",
    "    size=[1000, 920],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199ac76-9251-42c3-a715-bd731933e2dd",
   "metadata": {},
   "source": [
    "The method `get_data()` will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae52b6-7d58-4e26-b7ec-f0b155eca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_scar_imgs = request_burn_scar_map.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bc5d8-6262-4fa3-9bb0-4c5717a44877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Returned data is of type = {type(burn_scar_imgs)} and length {len(burn_scar_imgs)}.\"\n",
    ")\n",
    "print(\n",
    "    f\"Single element in the list is of type {type(burn_scar_imgs[-1])} and has shape {burn_scar_imgs[-1].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57bbffe-aac8-4161-9278-075c804f19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = burn_scar_imgs[0]\n",
    "print(f\"Image type: {image.dtype}\")\n",
    "\n",
    "# plot function\n",
    "plot_image(image, factor=1.5 / 255, clip_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec57be-13a6-4cdf-b4d5-5c7670ccf4cf",
   "metadata": {},
   "source": [
    "The detection of the burn scar is not perfect, but we can now see the spatial extent using the threshold we defined in the evalscript.\n",
    "\n",
    "#### Exercise:\n",
    "\n",
    "- Can you improve the detection of the burn scar in the above image? \n",
    "    - Hint: Can you find and adjust the parameter in the evalscript that does this or formulate your own method to do this.\n",
    "- If you have time, are you able to find a way to map severely burned and moderately burned areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff820c-7041-443a-b302-e22b265c389d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sentinel Hub",
   "language": "python",
   "name": "sentinelhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
